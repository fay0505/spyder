### 时间：
2017.9.2
### 目的：
爬取新闻网站的所有版面的新闻信息，将爬取的数据存储在数据库中，然后对数据进行清洗整理。最后利用jieba分词提取关键词，并用词云展示。
### 爬取网站：
解放日报、人民日报
### 效果展示：
![人民日报](https://github.com/fay0505/spyder/blob/master/people_paper/people_paper/1.png)
![解放日报](https://github.com/fay0505/spyder/blob/master/jfdaily/jfdaily/1.png)
